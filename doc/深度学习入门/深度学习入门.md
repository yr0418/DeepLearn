# 深度学习入门

---

## 1. demo01：神经网络基础

1. **NumPyTest:** NumPy 数组基础
2. **MatplotlibTest:** 图形绘制基础
3. **ActivationFunction:** 激活函数
4. **InitNetWork:** 一个简单的三层神经网络，课本56，3.4小节。
4. **OutputFunction:** 输出函数

![](深度学习入门.assets/三层神经网络.png)



### 输出层的设计

神经网络可以用在分类问题和回归问题上，根据需要改变输出层的激活函数。一般而言，回归问题用恒等函数，分类问题用 **softmax** 函数。

分类问题即数据属于哪一个类别的问题；回归问题是根据某个输入预测一个数值的问题。

输出层的神经元数量需要根据实际问题进行确定。对于分类问题，输出层的神经元数量一般设定为类别的数量。对于输出值，取其中的最大值对应的类别为最终的输出结果。

#### 1. 恒等函数

将输入原样输出。

#### 2. softmax 函数

函数式：
$$
y_k = \frac{exp(a_k)} {\sum_{i=1}^{n}{exp(a_i)}}
$$
假设输出层一共有 $n$ 个输出，计算第 $k$ 个神经元的输出 $y_k$，分子是输入信号 $a_k$ 的指数函数，分母是所有输入信号的指数函数的和。

使用 softmax 函数在计算时，容易产生 **溢出**，使得数据的计算难以正常运行，为此，对 softmax 进行改进。改进后的函数式如下：
$$
y_k = \frac{exp(a_k - max\{a_i\})} {\sum_{i=1}^{n}{exp(a_i- max\{a_i\}))}}
$$
**注意:** 

- $max\{a_i\}$ 即输入信号中的最大值。
- softmax 函数的输出总是 0.0 ~ 1.0 的实数，且所有输出值的总和为 **1**。为此，也将 softmax 函数的输出值称为 **概率**。
- softmax 函数不改变各个元素之间的大小关系。
